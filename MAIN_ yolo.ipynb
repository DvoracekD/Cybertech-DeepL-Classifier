{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from GenerateSyntheticDataset import generate_dataset\n",
    "import os\n",
    "import shutil\n",
    "from distutils.dir_util import copy_tree\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup variables for the run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d96d2a5eba9f86e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_NEW = True  # fail-safe so we don't overwrite our dataset\n",
    "GENERATE_NR_IMAGES = 50\n",
    "SEGMENTATION = True\n",
    "GENERATE_VIDEO = False\n",
    "results = {'Mode': 'Segmentation' if SEGMENTATION else 'Detection'}"
   ],
   "id": "795df926899e1986"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_NEW:\n",
    "    #check if \"/datasets\" exists, if it does, delete it\n",
    "    if os.path.isdir(\"./datasets\"):\n",
    "        print(\"Deleting old dataset...\")\n",
    "        #remove the old dataset\n",
    "        for filename in os.listdir(\"./datasets\"):\n",
    "            file_path = os.path.join(\"./datasets\", filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "    generate_dataset(custom_num_images=GENERATE_NR_IMAGES, segmentation=SEGMENTATION)\n",
    "\n",
    "    os.makedirs(\"./datasets\", exist_ok=True)\n",
    "    copy_tree(\"./GeneratedDataset/\", \"./datasets/GeneratedDataset\")\n"
   ],
   "id": "16bdfbf37c3e4485"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Video generation from images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6dba43dbc681750"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if GENERATE_VIDEO:\n",
    "    import cv2\n",
    "    import os\n",
    "    \n",
    "    image_folder = 'real_footage/Run1/color'\n",
    "    video_name = 'real_footage/Run1/run1.mp4'\n",
    "    \n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "    images.sort()\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    \n",
    "    video = cv2.VideoWriter(video_name, fourcc, 20.0, (width, height))\n",
    "    \n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "    \n",
    "    video.release()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5567c280a9f8b070"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Object detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e26e4e681ea44af4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "506f6bbb68ff4981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f193621aea489b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not SEGMENTATION:\n",
    "    from ultralytics import YOLO\n",
    "    import torch\n",
    "    import platform\n",
    "    \n",
    "    # Load already trained weights\n",
    "    \n",
    "    ###########\n",
    "    EPOCHS = 30\n",
    "    model_to_use = 'runs/detect/train5/weights/best.pt'  # use 'yolov8n.pt' to start fresh\n",
    "    ###########\n",
    "    \n",
    "    #if windows put \"/\" before model_to_use \n",
    "    curr_os = platform.system()\n",
    "    if curr_os == 'Windows':\n",
    "        model_to_use = '/' + model_to_use\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_to_use)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not found, retraining from scratch with YoloV8n\")\n",
    "        model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    #check if using cuda\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        model.cuda()\n",
    "    \n",
    "    #is os windows?\n",
    "    import os\n",
    "    import platform\n",
    "    \n",
    "    start = time.time()\n",
    "    if curr_os == 'Windows':\n",
    "        print('Using Windows')\n",
    "        res = model.train(data='generated_dataset_Win.yaml', epochs=EPOCHS, optimizer='SGD')\n",
    "    else:\n",
    "        print('Using Linux')\n",
    "        res = model.train(data='generated_dataset.yaml', epochs=EPOCHS, optimizer='SGD')\n",
    "    end = time.time()\n",
    "    \n",
    "    # Save the results\n",
    "    results['Epochs'] = EPOCHS\n",
    "    results['Time training'] = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92beea66c855dbe9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if SEGMENTATION:\n",
    "    from ultralytics import YOLO\n",
    "    import torch\n",
    "    import platform\n",
    "    \n",
    "    # Load already trained weights\n",
    "    \n",
    "    ###########\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 8\n",
    "    TRAIN = True\n",
    "    model_to_use = 'runs/segment/train13/weights/best.pt'  # use 'yolov8n-seg.pt' to start fresh\n",
    "    ###########\n",
    "    \n",
    "    #if windows put \"/\" before model_to_use \n",
    "    curr_os = platform.system()\n",
    "    if curr_os == 'Windows':\n",
    "        model_to_use = '/' + model_to_use\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_to_use)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not found, retraining from scratch with YoloV8n-seg\")\n",
    "        model = YOLO('yolov8n-seg.pt')\n",
    "    \n",
    "    #check if using cuda\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU\")\n",
    "        model.cuda()\n",
    "    \n",
    "    #is os windows?\n",
    "    import os\n",
    "    import platform\n",
    "    \n",
    "    if TRAIN:\n",
    "        start = time.time()\n",
    "        if curr_os == 'Windows':\n",
    "            print('Using Windows')\n",
    "            res = model.train(data='generated_dataset_Win.yaml', epochs=EPOCHS, batch=BATCH_SIZE, optimizer='SGD')\n",
    "        else:\n",
    "            print('Using Linux')\n",
    "            res = model.train(data='generated_dataset.yaml', epochs=EPOCHS, batch=BATCH_SIZE, optimizer='SGD')\n",
    "        end = time.time()\n",
    "        results['Time training'] = end - start\n",
    "    # Save the results\n",
    "    results['Epochs'] = EPOCHS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b565eaf8cda01015"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c7da5e53dae162"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create folder for results\n",
    "if not os.path.isdir('./results'):\n",
    "    os.makedirs('./results')\n",
    "# Save results in txt file\n",
    "with open(\"results/results.txt\", 'w') as f:  \n",
    "    for key, value in results.items():  \n",
    "        f.write('%s:%s\\n' % (key, value))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ced39a84200393af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random image result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "186073d6448258c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf9e0334d909aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "results = model('datasets/GeneratedDataset/images/val/image_0.png')  # results list\n",
    "\n",
    "# Show the results\n",
    "for r in results:\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    im.show()  # show image\n",
    "    im.save('results/results.jpg')  # save image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Real footage video result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24c2de76cbb99c1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a433229f1d169a2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Get the image shape\n",
    "frame = cv2.imread('real_footage/Run1/color/000000.png')\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"real_footage/Run1/run1.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "img_array = []\n",
    "\n",
    "# used to record the time when we processed last frame \n",
    "prev_frame_time = 0\n",
    "# used to record the time at which we processed current frame \n",
    "new_frame_time = 0\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (1750, 25)\n",
    "fontScale = 1\n",
    "fontColor = (0, 0, 255)\n",
    "thickness = 2\n",
    "lineType = 2\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        # time when we finish processing for this frame \n",
    "        new_frame_time = time.time()\n",
    "\n",
    "        # fps will be number of frame processed in given time frame \n",
    "        # since their will be the most time error of 0.001 second \n",
    "        # we will be subtracting it to get more accurate result \n",
    "        fps = 1 / (new_frame_time - prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "\n",
    "        # converting the fps into integer \n",
    "        fps = str(int(fps))\n",
    "\n",
    "        # putting the FPS count on the frame \n",
    "        cv2.putText(annotated_frame, 'FPS: ' + fps,\n",
    "                    bottomLeftCornerOfText,\n",
    "                    font,\n",
    "                    fontScale,\n",
    "                    fontColor,\n",
    "                    thickness,\n",
    "                    lineType)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "        img_array.append(annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "out = cv2.VideoWriter('results/real_footage.mp4', cv2.VideoWriter_fourcc(*'XVID'), 30.0,\n",
    "                      (width, height))\n",
    "#write video\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()\n",
    "print('Video created successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
